{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ad5bf67-3e97-4ad6-801a-ef63e5cd6770",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/torchvision/datapoints/__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "/root/miniconda3/lib/python3.8/site-packages/torchvision/transforms/v2/__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from typing import Optional, List, Any\n",
    "import torch\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.llms.base import LLM\n",
    "from langchain.callbacks.manager import CallbackManagerForLLMRun\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, GenerationConfig, TextIteratorStreamer, AutoProcessor\n",
    "# from modelscope import AutoTokenizer, AutoModelForCausalLM, GenerationConfig\n",
    "from langchain import HuggingFacePipeline\n",
    "from langchain.chains import RetrievalQA, ConversationalRetrievalChain\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.outputs.generation import GenerationChunk\n",
    "from torch import device\n",
    "import time\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain.chains.history_aware_retriever import create_history_aware_retriever\n",
    "\n",
    "from langchain.chains.retrieval import create_retrieval_chain\n",
    "from langchain_core.runnables import RunnableWithMessageHistory\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "\n",
    "from threading import Thread\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763a10e4-9884-42a2-aade-0ebfe71c8ce8",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 该部分代码实现\n",
    "## 1.历史记录聊天\n",
    "## 2.实体提取\n",
    "## 3.意图识别\n",
    "## 4.主体模型qwen2.5-7B-instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d60fd1-f0c0-478f-a679-1cfd7d1e2349",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6cb65caa-1919-4599-bc5d-9023aec1081c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 构建模型\n",
    "class QianWenLLM(LLM):\n",
    "    # 基于本地的QianWen7B-Chat模型自定义LLM类\n",
    "    tokenizer: AutoTokenizer = None\n",
    "    model: AutoModelForCausalLM = None\n",
    "    processor: AutoProcessor = None\n",
    "    \n",
    "    def __init__(self, model_dir: str):\n",
    "        # 从本地加载模型\n",
    "        super().__init__()\n",
    "        print('正从本地加载模型。。。。。')\n",
    "\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\n",
    "            pretrained_model_name_or_path=model_dir,\n",
    "            trust_remote_code=True,\n",
    "        )\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(\n",
    "            pretrained_model_name_or_path=model_dir,\n",
    "            device_map='auto',\n",
    "            trust_remote_code=True,\n",
    "            # torch_dtype=torch.bfloat16,\n",
    "            # temperature=0.1\n",
    "            )\n",
    "        self.model = self.model.eval()\n",
    "        self.model.generation_config = GenerationConfig.from_pretrained(\n",
    "            model_dir,\n",
    "            trust_remote_code=True\n",
    "        )\n",
    "        # 可指定不同的生成长度、top_p等相关超参\n",
    "        self.processor = AutoProcessor.from_pretrained(model_dir)\n",
    "        print('模型加载完成！')\n",
    "\n",
    "    def _call(self, messages,\n",
    "              stop: Optional[List[str]] = None,\n",
    "              run_manager: Optional[CallbackManagerForLLMRun] = None,\n",
    "              **kwargs: Any):\n",
    "        # response, history = self.model.chat(self.tokenizer, prompt, history=[])\n",
    "        if type(messages) == str:\n",
    "            system_info =  messages.split('System:')[-1].split('Human:')[0].strip()\n",
    "            human_info =  messages.split('Human:')[-1].strip()\n",
    "            re_prompt = [\n",
    "                    {'role':'system', 'content': system_info},\n",
    "                    {'role':'user', 'content': human_info}\n",
    "                    ]\n",
    "            messages = re_prompt\n",
    "        # print('打印messages内容：', messages)\n",
    "        text = self.tokenizer.apply_chat_template(\n",
    "            messages,\n",
    "            tokenize=False,\n",
    "            add_generation_prompt=True\n",
    "        )\n",
    "        model_inputs = self.tokenizer([text], return_tensors='pt').to('cpu')\n",
    "        generated_ids = self.model.generate(\n",
    "            **model_inputs,\n",
    "            max_new_tokens=512\n",
    "        )\n",
    "        generated_ids = [\n",
    "            output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "        ]\n",
    "\n",
    "        response = self.tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "        \n",
    "        return response\n",
    "        \n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        return \"QwenLM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6fd3130-b11d-492c-98c2-9a046aff37fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 构建改写问题prompt\n",
    "\n",
    "# 请根据聊天历史和最后用户的问题，改写用户最终剔除的问题。\n",
    "# 你只需要改写用户最终的问题，请不要回答问题。\n",
    "# 没有聊天历史则将用户问题直接返回，有聊天历史则改写。\n",
    "    \n",
    "def contextualize_question_prompt():\n",
    "    system_prompt = \"\"\"\\\n",
    "    根据聊天历史和输入文本，改写输入文本。请根据工作流程和工作要求改写文本。\n",
    "\n",
    "    工作流程：\n",
    "    1-判断聊天历史是否为空。内容为空直接返回输入文本，否则继续以下工作流程。\n",
    "    2-聊天历史存在内容，请根据聊天历史和输入文本内容相关程度，改写输入文本。如果相关程度低则直接输出文本。\n",
    "    3-请思考改写后的输入文本内容，是否突出用户文本意图，否则重新根据用户问题改写。请注意如果是打招呼等日常用语也直接返回用户问题。\n",
    "    4-请不要回答输入的文本，输出改写的文本内容。\n",
    "\n",
    "    工作要求：\n",
    "    1-你只需要改写文本。\n",
    "    2-聊天历史为空则将输入文本直接返回，有聊天历史则改写。    \n",
    "    \"\"\"\n",
    "    contextualize_question_prompt = ChatPromptTemplate(\n",
    "        [\n",
    "        ('system', system_prompt),\n",
    "        MessagesPlaceholder('chat_history'),\n",
    "        ('human', '{input}')\n",
    "        ]\n",
    "    )\n",
    "    return contextualize_question_prompt\n",
    "\n",
    "def answer_prompt():\n",
    "    # 构建正常问答prompt\n",
    "    system_prompt = \"\"\"\\\n",
    "    使用上下文来回答最后的问题。如果你不知道答案，就说你不知道，不要试图编造答案。\n",
    "    {context}\n",
    "    \"\"\"\n",
    "    # 问题: {question}\n",
    "    # 有用的回答:\n",
    "    \n",
    "    qa_prompt = ChatPromptTemplate(\n",
    "    [\n",
    "    ('system', system_prompt),\n",
    "        MessagesPlaceholder('chat_history'),\n",
    "        ('human', '{input}')\n",
    "    ]\n",
    "    )\n",
    "    return qa_prompt\n",
    "\n",
    "store = {}\n",
    "# 构造存储函数\n",
    "def get_session_history(session_id: str):\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d379e00-210e-4884-b465-f1a772301df5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def init_model():\n",
    "    # 初始化模型\n",
    "    # model_cache_path = r'autodl-tmp/Qwen/Qwen-7B-Chat'\n",
    "    model_cache_path = r'autodl-tmp/Qwen/Qwen2.5-7B-Instruct'\n",
    "    llm = QianWenLLM(model_dir=model_cache_path)\n",
    "    return llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68462e5d-7a04-4994-b38d-661abc216427",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def init_db():\n",
    "    persist_directory = r'vectordb/chroma'\n",
    "    embeddings_model_cache_path = r'autodl-tmp/embedding_model/Ceceliachenen/paraphrase-multilingual-MiniLM-L12-v2'\n",
    "    # 加载词向量模型\n",
    "    embeddings = HuggingFaceEmbeddings(\n",
    "        model_name=embeddings_model_cache_path)\n",
    "    # 加载缓存知识库\n",
    "    vectordb = Chroma(\n",
    "        persist_directory=persist_directory,\n",
    "        embedding_function=embeddings,\n",
    "    )\n",
    "    return vectordb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d10f82cf-4182-4d77-8a06-296662d2caa3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def intention_recognition(question: str, llm):\n",
    "    template = f\"\"\"\n",
    "        你是一名实体提取和意图识别分类领域专家，请严格遵循以下任务和工作流程的指示输出结果。\n",
    "        \n",
    "        任务：\n",
    "        1-判断用户问题是否存在实体。\n",
    "        2-抽取用户问题所有实体。\n",
    "        3-根据实体与给出的意图标签进行判定该用户问题的意图。\n",
    "        \n",
    "        意图标签：政策知识，日常知识，招中标知识\n",
    "        \n",
    "        工作流程：\n",
    "        1.-先判断是否存在实体，不存在实体则直接根据不存在实体输出格式输出，存在实体则继续以下工作流程，并通过存在实体输出格式输出。\n",
    "        2-实体提取：请从用户问题中提取出所有实体。\n",
    "        3-意图分类：请根据第2点提取的实体以及意图标签，进行意图识别并分类用户问题。\n",
    "        \n",
    "        不存在实体输出格式：\n",
    "            实体提取:[]\n",
    "            意图分类:日常知识\n",
    "            \n",
    "        存在实体输出格式：\n",
    "            实体提取：[实体1, 实体2, ...]\n",
    "            意图分类：意图标签\n",
    "            \n",
    "        有用的回答：\n",
    "       \"\"\"\n",
    "          # 4. 意图分类：根据第3点的意图识别结果分类，意图标签：[政策知识，日常知识，招中标知识]。       2.意图识别：[意图1, 意图2, ...]。\n",
    "    # ，例如日常、政策、设备、建筑、维修等\n",
    "    messages = [\n",
    "            {'role':'system', 'content': template},\n",
    "            {'role':'user', 'content':question}]\n",
    "\n",
    "    response = llm._call(messages)\n",
    "    print('实体+意图模型结果：', response)\n",
    "    target = response.split('意图分类：')[-1]\n",
    "    # print('模型实体+意图结果：', response)\n",
    "    # print('意图分类:', target)\n",
    "    return target\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b9f8397-d128-4dbc-a209-746e34a9828b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def qa_chain(rag_chain, get_session_history):\n",
    "    \"\"\"\n",
    "    构建问答链\n",
    "    :param persist_directory: 知识库本地保存路径，这里初始化政策信息知识库\n",
    "    :return: 返回调用LLM回答\n",
    "    \"\"\"\n",
    "    # 包装\n",
    "    conversational_rag_chain = RunnableWithMessageHistory(\n",
    "        runnable=rag_chain,\n",
    "        get_session_history=get_session_history,\n",
    "        input_messages_key='input',\n",
    "        history_messages_key='chat_history',\n",
    "        output_messages_key='answer'\n",
    "    )\n",
    "\n",
    "    return conversational_rag_chain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ce3be43-5e17-4dcc-8baa-c07ce17c75b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def contextualize_question_chain(llm):\n",
    "    # 根据历史检索器原理，我们这里只要llm和改写prompt和历史记录就行\n",
    "    question_prompt = contextualize_question_prompt()\n",
    "    contextualize_question_chain = RunnableWithMessageHistory(\n",
    "        question_prompt | llm,\n",
    "        get_session_history,\n",
    "        input_messages_key=\"input\",\n",
    "        history_messages_key=\"chat_history\"\n",
    "    )\n",
    "    return contextualize_question_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "333bcc19-cc3e-42c7-8655-8fa8630b372c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 链接前面的函数\n",
    "class Model_center():\n",
    "    \"\"\"\n",
    "      存储问答 Chain 的对象\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ):\n",
    "        print('初始化模型+知识库。。。。')\n",
    "        self.model = init_model()\n",
    "        self.db = init_db()\n",
    "         # 因为历史记录问题进行问题改写再传到模型\n",
    "        self.question_prompt = contextualize_question_prompt()\n",
    "        # 历史对话巡回器\n",
    "        self.history_aware_retriever = create_history_aware_retriever(self.model, \n",
    "                                                                self.db.as_retriever(), \n",
    "                                                                 self.question_prompt)\n",
    "        self.qa_prompt = answer_prompt()\n",
    "        self.qa_chain = create_stuff_documents_chain(self.model, self.qa_prompt)\n",
    "        self.rag_chain = create_retrieval_chain(self.history_aware_retriever, self.qa_chain)\n",
    "        \n",
    "\n",
    "    def qa_chain_self_answer(self, question: str, chat_history: list = []):\n",
    "        # print('调用问答链')\n",
    "        # print('打印用户问题', question)\n",
    "        if question == None or len(question) < 1:\n",
    "            print('问答为空。。。。')\n",
    "            return '', chat_history\n",
    "        print('实体提取+意图识别。。。。')\n",
    "\n",
    "        # for question in sentence:\n",
    "        # try\n",
    "        # print('用户输入问题：', question)\n",
    "        target = intention_recognition(question, self.model)\n",
    "        print('意图识别成功。。。。')\n",
    "        # except:\n",
    "            # print('实体提取+意图识别步骤失败。。。。')\n",
    "\n",
    "\n",
    "        if target == '招中标知识' or target == '政策知识':\n",
    "            print('调用检索问答链。。。。')\n",
    "            # print('知识库:', target)\n",
    "            # 带langchain实力对话共能\n",
    "            response = qa_chain(\n",
    "                self.rag_chain,\n",
    "                get_session_history).invoke(\n",
    "                    {'input': question},\n",
    "                    config={'configurable':{'session_id':'test123'}}\n",
    "                    )\n",
    "            print('调用检索问答链输出response：', response['context'][0].page_content)\n",
    "\n",
    "        else:\n",
    "            \n",
    "            print('调用简单模型。。。。')\n",
    "            \n",
    "            # 改写问题\n",
    "            \n",
    "            # 将改写的新问题输入进行回答\n",
    "            new_question = contextualize_question_chain(self.model).invoke( \n",
    "                {'input': question},\n",
    "                config={'configurable':{'session_id':'test123'}}\n",
    "                    )\n",
    "            print('用户问题：', question)\n",
    "            print('根据历史聊天记录改写用户问题：', new_question)\n",
    "\n",
    "            template = \"\"\"\\\n",
    "                        请回答用户的问题，如果你不知道答案，就说你不知道，不要试图编造答案。\n",
    "                    \"\"\"\n",
    "            messages = [\n",
    "                {'role':'system', 'content': template},\n",
    "                {'role':'user', 'content':new_question}\n",
    "                ]\n",
    "            print('改写前的问题：', question, '改写后的问题：', new_question)\n",
    "            response = self.model._call(messages)\n",
    "            store['test123'].add_user_message(question)\n",
    "            store['test123'].add_ai_message(response)\n",
    "        print(f'意图分类：{target}，测试问题：{question}，返回结果：{response}')\n",
    "\n",
    "    # print('简单模型输出格式：', type(response))\n",
    "        # 结果调用下流式输出    target == '日常知识':\n",
    "        \n",
    "        \n",
    "        # 检索问答链+历史聊天组件\n",
    "        # response = self.qa_chain.invoke({'query': question, 'chat_history': chat_history})['answer']\n",
    "\n",
    "        chat_history.append([question, response])\n",
    "        # print(chat_history)\n",
    "        return '', chat_history\n",
    "                \n",
    "        # except Exception as e:\n",
    "        #     print('问答链报错', e)\n",
    "        #     return e, chat_history\n",
    "\n",
    "    def clear_history(self):\n",
    "        self.qa_chain.clear_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7abcb68b-dbaa-4139-941b-37014e7d7c2a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "初始化模型+知识库。。。。\n",
      "正从本地加载模型。。。。。\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "505e0bb369154165844d3ec6af349339",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device because they were offloaded to the cpu.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型加载完成！\n",
      "进度1\n",
      "进度2\n",
      "Running on local URL:  http://127.0.0.1:6010\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:6010/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPORTANT: You are using gradio version 3.50.2, however version 4.44.1 is available, please upgrade.\n",
      "--------\n",
      "实体提取+意图识别。。。。\n",
      "实体+意图模型结果： 实体提取：投标文件，招标人\n",
      "\n",
      "意图分类：招中标知识\n",
      "意图识别成功。。。。\n",
      "调用检索问答链。。。。\n",
      "调用检索问答链输出response： 络或者其他媒介发布的招标文件与书面招标文件具有同等法律效力，出现不一致时以书面招标文件为准，国家另有规定的除外。对招标文件或者资格预审文件的收费应当限于补偿印刷、邮寄的成本支出，不得以营利为目的。对于所附的设计文件，招标人可以向投标人酌收押金；对于开标后投标人退还设计文件的，招标人应当向投标人退还押金。招标文件或者资格预审文件售出后，不予退还。除不可抗力原因外，招标人在发布招标公告、发出投标邀请书后或者售出招标文件或资格预审文件后不得终止招标。第十六条招标人可以根据招标项目本身的特点和需要，要求潜在投标人或者投标人提供满足其资格要求的文件，对潜在投标人或者投标人进行资格审查；国家对潜在投标人或者投标人的资格条件有规定的，依照其规定。第十七条资格审查分为资格预审和资格后审。资格预审，是指在投标前对潜在投标人进行的资格审查。资格后审，是指在开标后对投标人进行的资格审查。进行资格预审的，一般不再进行资格后审，但招标文件另有规定的除外。第十八条采取资格预审的，招标人应当发布资格预审公告。资格预审公告适用本办法第十三条、第十四条有关招标公告的规定。采取资格预审的，招标人应当在资格预审文件中载明资格预审的条件、标准和方法；采取资格后审的，招标人应当在招标文件中载明对投标人资格要求的条件、标准和方法。招标人不得改变载明的资格条件或者以没有载明的资格条件对潜在投标人或者投标人进行资格审查。第十九条经资格预审后，招标人应当向资格预审合格的潜在投标人发出资格预审合格通知书，告知获取招标文件的时间、地点和方法，并同时向资格预审不合格的潜在投标人告知资格预审结果。资格预审不合格的潜在投标人不得参加投标。经资格后审不合格的投标人的投标应予否决。第二十条资格审查应主要审查潜在投标人或者投标人是否符合下列条件：（一）具有独立订立合同的权利；（二）具有履行合同的能力，包括专业、技术资格和能力，资金、设备和其他物质设施状况，管理能力，经验、信誉和相应的从业人员；（三）没有处于被责令停业，投标资格被取消，财产被接管、冻结，破产状态；（四）在最近三年内没有骗取中标和严重违约及重大工程质量问题；（五）国家规定的其他资格条件。资格审查时，招标人不得以不合理的条件限制、排斥潜在投标人或者投标人，不得对潜在投标人或者投标人实行歧视待遇。任何单位和个人不得以行政手段或者其他不合理方式限制投标人的数量。第二十一条招\n",
      "意图分类：招中标知识，测试问题：如果投标文件解密失败，招标人是否有义务提供补救方案？，返回结果：{'input': '如果投标文件解密失败，招标人是否有义务提供补救方案？', 'chat_history': [], 'context': [Document(page_content='络或者其他媒介发布的招标文件与书面招标文件具有同等法律效力，出现不一致时以书面招标文件为准，国家另有规定的除外。对招标文件或者资格预审文件的收费应当限于补偿印刷、邮寄的成本支出，不得以营利为目的。对于所附的设计文件，招标人可以向投标人酌收押金；对于开标后投标人退还设计文件的，招标人应当向投标人退还押金。招标文件或者资格预审文件售出后，不予退还。除不可抗力原因外，招标人在发布招标公告、发出投标邀请书后或者售出招标文件或资格预审文件后不得终止招标。第十六条招标人可以根据招标项目本身的特点和需要，要求潜在投标人或者投标人提供满足其资格要求的文件，对潜在投标人或者投标人进行资格审查；国家对潜在投标人或者投标人的资格条件有规定的，依照其规定。第十七条资格审查分为资格预审和资格后审。资格预审，是指在投标前对潜在投标人进行的资格审查。资格后审，是指在开标后对投标人进行的资格审查。进行资格预审的，一般不再进行资格后审，但招标文件另有规定的除外。第十八条采取资格预审的，招标人应当发布资格预审公告。资格预审公告适用本办法第十三条、第十四条有关招标公告的规定。采取资格预审的，招标人应当在资格预审文件中载明资格预审的条件、标准和方法；采取资格后审的，招标人应当在招标文件中载明对投标人资格要求的条件、标准和方法。招标人不得改变载明的资格条件或者以没有载明的资格条件对潜在投标人或者投标人进行资格审查。第十九条经资格预审后，招标人应当向资格预审合格的潜在投标人发出资格预审合格通知书，告知获取招标文件的时间、地点和方法，并同时向资格预审不合格的潜在投标人告知资格预审结果。资格预审不合格的潜在投标人不得参加投标。经资格后审不合格的投标人的投标应予否决。第二十条资格审查应主要审查潜在投标人或者投标人是否符合下列条件：（一）具有独立订立合同的权利；（二）具有履行合同的能力，包括专业、技术资格和能力，资金、设备和其他物质设施状况，管理能力，经验、信誉和相应的从业人员；（三）没有处于被责令停业，投标资格被取消，财产被接管、冻结，破产状态；（四）在最近三年内没有骗取中标和严重违约及重大工程质量问题；（五）国家规定的其他资格条件。资格审查时，招标人不得以不合理的条件限制、排斥潜在投标人或者投标人，不得对潜在投标人或者投标人实行歧视待遇。任何单位和个人不得以行政手段或者其他不合理方式限制投标人的数量。第二十一条招'), Document(page_content='投标人少于3个的，不得开标，投标文件应当当场退还给投标人；招标人应当重新招标。第三十六条开标由招标人主持，邀请所有投标人参加。开标过程应当记录，并存档备查。投标人对开标有异议的，应当在开标现场提出，招标人应当当场作出答复，并制作记录。未参加开标的投标人，视为对开标过程无异议。第三十七条投标文件按照招标文件规定采用双信封形式密封的，开标分两个步骤公开进行：第一步骤对第一信封内的商务文件和技术文件进行开标，对第二信封不予拆封并由招标人予以封存；第二步骤宣布通过商务文件和技术文件评审的投标人名单，对其第二信封内的报价文件进行开标，宣读投标报价。未通过商务文件和技术文件评审的，对其第二信封不予拆封，并当场退还给投标人；投标人未参加第二信封开标的，招标人应当在评标结束后及时将第二信封原封退还投标人。第三十八条招标人应当按照国家有关规定组建评标委员会负责评标工作。国家审批或者核准的高速公路、一级公路、独立桥梁和独立隧道项目，评标委员会专家应当由招标人从国家重点公路工程建设项目评标专家库相关专业中随机抽取；其他公路工程建设项目的评标委员会专家可以从省级公路工程建设项目评标专家库相关专业中随机抽取，也可以从国家重点公路工程建设项目评标专家库相关专业中随机抽取。对于技术复杂、专业性强或者国家有特殊要求，采取随机抽取方式确定的评标专家难以保证胜任评标工作的特殊招标项目，可以由招标人直接确定。第三十九条交通运输部负责国家重点公路工程建设项目评标专家库的管理工作。省级人民政府交通运输主管部门负责本行政区域公路工程建设项目评标专家库的管理工作。第四十条评标委员会应当民主推荐一名主任委员，负责组织评标委员会成员开展评标工作。评标委员会主任委员与评标委员会的其他成员享有同等权利与义务。第四十一条招标人应当向评标委员会提供评标所必需的信息，但不得明示或者暗示其倾向或者排斥特定投标人。评标所必需的信息主要包括招标文件、招标文件的澄清或者修改、开标记录、投标文件、资格预审文件。招标人可以协助评标委员会开展下列工作并提供相关信息：（一）根据招标文件，编制评标使用的相应表格；（二）对投标报价进行算术性校核；（三）以评标标准和方法为依据，列出投标文件相对于招标文件的所有偏差，并进行归类汇总；（四）查询公路建设市场信用信息管理系统，对投标人的资质、业绩、主要人员资历和目前在岗情况、信用等级进行核实。招标人不得'), Document(page_content='取投标保证金的，招标人应当及时退还所收取的购买资格预审文件、招标文件的费用，以及所收取的投标保证金及银行同期存款利息。利息的计算方法应当在招标文件中载明。第三十四条招标人不得以不合理的条件限制、排斥潜在投标人或者投标人。招标人有下列行为之一的，属于以不合理条件限制、排斥潜在投标人或者投标人：（一）就同一招标项目向潜在投标人或者投标人提供有差别的项目信息；（二）设定的资格、技术、商务条件与招标项目的具体特点和实际需要不相适应或者与合同履行无关；（三）依法必须进行招标的项目以特定行政区域或者特定行业的业绩、奖项作为加分条件或者中标条件；（四）对潜在投标人或者投标人采取不同的资格审查或者评标标准；（五）限定或者指定特定的专利、商标、品牌、原产地或者供应商；（六）依法必须进行招标的项目非法限定潜在投标人或者投标人的所有制形式或者组织形式；（七）以其他不合理条件限制、排斥潜在投标人或者投标人。第三章投标第三十五条与招标人存在利害关系可能影响招标公正性的法人、其他组织或者个人，不得参加投标。单位负责人为同一人或者存在控股、管理关系的不同单位，不得参加同一标段投标或者未划分标段的同一招标项目投标。施工投标人与本标段的设计人、监理人、代建人或招标代理机构不得为同一个法定代表人、存在相互控股或参股或法定代表人相互任职、工作。违反上述规定的，相关投标均无效。第三十六条投标人可以按照招标文件的要求由两个以上法人或者其他组织组成一个联合体，以一个投标人的身份共同投标。国家有关规定或者招标文件对投标人资格条件有规定的，联合体各方均应当具备规定的相应资格条件，资格条件考核以联合体协议书中约定的分工为依据。由同一专业的单位组成的联合体，按照资质等级较低的单位确定资质等级。联合体成员间应签订共同投标协议，明确牵头人以及各方的责任、权利和义务，并将协议连同资格预审申请文件、投标文件一并提交招标人。联合体各方签署联合体协议后，不得再以自己名义单独或者参加其他联合体在同一招标项目中投标。联合体中标的，联合体各方应当共同与招标人签订合同，就中标项目向招标人承担连带责任。招标人不得强制投标人组成联合体共同投标。第三十七条投标人发生合并、分立、破产等重大变化的，应当及时书面告知招标人。投标人不再具备资格预审文件、招标文件规定的资格条件或者投标影响公正性的，其投标无效。招标人接受联合体投标并进行资格预审的，联合'), Document(page_content='考。第二十三条投标有效期从提交投标文件的截止之日起算。投标文件中承诺的投标有效期应当不少于招标文件中载明的投标有效期。投标有效期内投标人撤销投标文件的，采购人或者采购代理机构可以不退还投标保证金。第二十四条招标文件售价应当按照弥补制作、邮寄成本的原则确定，不得以营利为目的，不得以招标采购金额作为确定招标文件售价的依据。第二十五条招标文件、资格预审文件的内容不得违反法律、行政法规、强制性标准、政府采购政策，或者违反公开透明、公平竞争、公正和诚实信用原则。有前款规定情形，影响潜在投标人投标或者资格预审结果的，采购人或者采购代理机构应当修改招标文件或者资格预审文件后重新招标。第二十六条采购人或者采购代理机构可以在招标文件提供期限截止后，组织已获取招标文件的潜在投标人现场考察或者召开开标前答疑会。组织现场考察或者召开答疑会的，应当在招标文件中载明，或者在招标文件提供期限截止后以书面形式通知所有获取招标文件的潜在投标人。第二十七条采购人或者采购代理机构可以对已发出的招标文件、资格预审文件、投标邀请书进行必要的澄清或者修改，但不得改变采购标的和资格条件。澄清或者修改应当在原公告发布媒体上发布澄清公告。澄清或者修改的内容为招标文件、资格预审文件、投标邀请书的组成部分。澄清或者修改的内容可能影响投标文件编制的，采购人或者采购代理机构应当在投标截止时间至少15日前，以书面形式通知所有获取招标文件的潜在投标人；不足15日的，采购人或者采购代理机构应当顺延提交投标文件的截止时间。澄清或者修改的内容可能影响资格预审申请文件编制的，采购人或者采购代理机构应当在提交资格预审申请文件截止时间至少3日前，以书面形式通知所有获取资格预审文件的潜在投标人；不足3日的，采购人或者采购代理机构应当顺延提交资格预审申请文件的截止时间。第二十八条投标截止时间前，采购人、采购代理机构和有关人员不得向他人透露已获取招标文件的潜在投标人的名称、数量以及可能影响公平竞争的有关招标投标的其他情况。第二十九条采购人、采购代理机构在发布招标公告、资格预审公告或者发出投标邀请书后，除因重大变故采购任务取消情况外，不得擅自终止招标活动。终止招标的，采购人或者采购代理机构应当及时在原公告发布媒体上发布终止公告，以书面形式通知已经获取招标文件、资格预审文件或者被邀请的潜在投标人，并将项目实施情况和采购任务取消原因报告本级财政部门。')], 'answer': '根据提供的信息，关于投标文件解密失败时招标人是否需要提供补救方案，并没有直接的相关规定。提供的内容giuo了关于招标文件的发布、投标资格审查、开标、评标等一系列程序的规定，但并未涉及投标文件解密失败的具体处理措施。\\n\\n在实际操作中，招标人通常会在招标文件中明确规定如何处理电子投标文件的各种问题，包括解密失败的情况。如果招标文件中有相关条款说明了此类问题的处理办法，则招标人应当按照招标文件的规定执行。如果没有明确规定，招标人可以参照电子招标投标的相关法律法规，采取合理的补救措施，比如延长解密时间、允许投标人重新提交解密后的文件等。\\n\\n因此，具体的补救方案取决于招标文件中的约定和相关法律法规的要求。如果招标文件中对此没有明确规定，招标人应当咨询相关的(pages: 1074)法律法规或寻求法律顾问的意见，以确保处理方式合法合规。'}\n"
     ]
    }
   ],
   "source": [
    "model_center = Model_center()\n",
    "def update_chatbot(question, chat_history):\n",
    "    for char in model_center.qa_chain_self_answer(question, chat_history):\n",
    "        gr.update(value=chat_history)\n",
    "        chat_history.append((question, char))\n",
    "    return chat_history\n",
    "# def demo():\n",
    "block = gr.Blocks()\n",
    "with block as demo:\n",
    "    with gr.Row(equal_height=True):  # 水平排列子组件\n",
    "        with gr.Column(scale=15):  # 垂直排列子组件\n",
    "            gr.Markdown(\"\"\"<h1><center>QwenLM7B-Chat</center></h1><center>科大讯飞实践-招中标政策智能问答助手</center>\"\"\")\n",
    "\n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=4):\n",
    "            # 创建聊天界面的组件。height=450 参数设置了聊天界面的高度为 450 像素。\n",
    "            # show_copy_button=True参数表示在聊天界面中显示一个复制按钮，允许用户复制聊天内容\n",
    "            chatbot = gr.Chatbot(height=450, show_copy_button=True)\n",
    "            # 创建一个文本框组件，用于输入 prompts。\n",
    "            msg = gr.Textbox(label='Prompt/问题')\n",
    "\n",
    "            with gr.Row():\n",
    "                # 创建提交按钮\n",
    "                db_wo_his_btn = gr.Button('Chat')\n",
    "            with gr.Row():\n",
    "                # 创建一个清除按钮，用于清除聊天机器人组件的内容。\n",
    "                clear_btn = gr.ClearButton(components=[chatbot], value='Clear console')\n",
    "\n",
    "        # 设置按钮的点击事件。当点击时，调用上面定义的 qa_chain_self_answer 函数，并传入用户的消息和聊天历史记录，然后更新文本框和聊天机器人组件。\n",
    "        print('进度1')\n",
    "        # 设置流式输出\n",
    "        def bot(question, history):\n",
    "            # print('bot_question',question)\n",
    "            # print('bot_history',history)\n",
    "            curr, response = model_center.qa_chain_self_answer(question, history)\n",
    "            # print('response', response)\n",
    "            # print('curr', curr)\n",
    "            history = response\n",
    "            bot_message = history[-1][1]\n",
    "            # print('bot_message', bot_message)\n",
    "            history[-1][1] = ''\n",
    "            for character in bot_message:\n",
    "                history[-1][1] += character\n",
    "                # print(f'累计中：{history}')\n",
    "                time.sleep(0.1)\n",
    "                yield '', history\n",
    "        \n",
    "        db_wo_his_btn.click(bot, inputs=[msg, chatbot], outputs=[msg, chatbot])\n",
    "\n",
    "        print('进度2')\n",
    "        # 点击后清空后端存储的聊天记录\n",
    "        clear_btn.click(model_center.clear_history)\n",
    "\n",
    "    # 填写注意事项\n",
    "    gr.Markdown(\n",
    "        \"\"\"\n",
    "        提醒：<br>\n",
    "        1. 初始化数据库实践可能较长，请耐心等待。\n",
    "        2. 使用中如果出现异常，将会在文本输入框进行展示，请不要惊慌。 <br>\n",
    "        \"\"\"\n",
    "    )\n",
    "# gr.close_all()\n",
    "# 直接启动\n",
    "demo.queue()\n",
    "demo.launch(server_name='127.0.0.1', server_port=6010)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa35931c-ac49-44fd-aa81-a3a782af46a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sentence = [\n",
    "            '你好',\n",
    "            '你是谁？',\n",
    "            '上海联合产权交易所有限公司物权交易操作指引(沪联产交〔2020〕26号)',\n",
    "            '周杰伦是谁？',\n",
    "            '产权交易争议调解',\n",
    "            '2023年7月，中国航天科技集团公司五院研制的长征十二号运载火箭在酒泉卫星发射中心成功发射，将一颗北斗导航卫星送入预定轨道。',\n",
    "            '周杰伦的歌曲《稻香》是谁写的？',\n",
    "            '项目名称为ABC，中标金额为500万元，供应商为XYZ公司。']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3966af8-c640-48ba-a724-96b0e6e0d008",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = f\"\"\"\n",
    "        你是一名实体提取和意图识别分类领域专家，请严格遵循以下任务和工作流程的指示输出结果。\n",
    "        \n",
    "        任务：\n",
    "        1-判断输入文本是否存在实体。\n",
    "        2-抽取输入文本所有实体。\n",
    "        3-根据实体与给出的意图标签进行判定该输入文本的意图。\n",
    "        \n",
    "        意图标签：政策知识，日常知识，招中标知识\n",
    "        \n",
    "        工作流程：\n",
    "        1.-先判断是否存在实体，不存在实体则直接根据不存在实体输出格式输出，存在实体则继续以下工作流程，并通过存在实体输出格式输出。\n",
    "        2-实体提取：请从输入的文本中提取出所有实体。\n",
    "        3-意图分类：请根据第2点提取的实体以及意图标签，进行意图识别并分类输入文本。\n",
    "        \n",
    "        输入文本：{question}\n",
    "        不存在实体输出格式：\n",
    "            实体提取:[]\n",
    "            意图分类:日常知识\n",
    "        存在实体输出格式：\n",
    "            实体提取：[实体1, 实体2, ...]\n",
    "            意图分类：意图标签\n",
    "\n",
    "        有用的回答：\n",
    "       \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ace048e1-5191-4166-be97-729782208350",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'chat_history_' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mchat_history_\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'chat_history_' is not defined"
     ]
    }
   ],
   "source": [
    "question_prompt = f\"\"\"\\\n",
    "    根据聊天历史和用户问题，改写用户问题。请根据工作流程和工作要求改写问题。\n",
    "\n",
    "    工作流程：\n",
    "    1-判断聊天历史是否为空。内容为空直接返回用户的问题，否则继续以下工作流程。\n",
    "    2-聊天历史存在内容，请根据聊天历史和用户的问题，改写用户提出的问题。\n",
    "    3-请思考改写后的问题内容，是否突出用户问题意图，否则重新根据用户问题改写。请注意如果是打招呼等日常用语也直接返回用户问题。\n",
    "    4-请不要回答用户的问题，输出改写的问题。\n",
    "\n",
    "    工作要求：\n",
    "    1-你只需要改写用户的问题。\n",
    "    2-聊天历史为空则将用户问题直接返回，有聊天历史则改写。                         \n",
    "\n",
    "    聊天历史：{chat_history_}\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d39910ea-f7ef-4bb1-98ea-6bfbeb445b9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def history():\n",
    "    MessagesPlaceholder('chat_history')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d4078d7-c2ff-4691-a187-051ec0961e8f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'response' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mresponse\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'response' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c0af2a2b-ff50-4cc4-b7c9-763a86ebdc56",
   "metadata": {},
   "source": [
    "Mess"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
